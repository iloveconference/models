{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from datetime import datetime\n",
    "from langchain.schema.document import Document\n",
    "from models.load_utils import load_docs_from_jsonl, save_docs_to_jsonl\n",
    "from models.split_markdown import RecursiveMarkdownTextSplitter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path  = '../data/raw/pearl_study/pgp_study_edition_stephen_o_smoot.pdf'\n",
    "output_dir = '../data/load/pearl_study/'\n",
    "\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(path)\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = os.path.join(output_dir, f\"{today}.jsonl\")\n",
    "\n",
    "save_docs_to_jsonl(pages, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure\n",
    "input_path = '../data/load/pearl_study/2023-11-08.jsonl'\n",
    "chunk_size = 2000\n",
    "chunk_overlap = 200\n",
    "output_dir_split = '../data/split/pearl_study/'\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "if not os.path.exists(output_dir_split):\n",
    "    os.makedirs(output_dir_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pages(pages, verbose: bool = False) -> Document:\n",
    "    \"\"\"Load dc people from a url and html.\"\"\"\n",
    "\n",
    "    docs = []\n",
    "    for page in pages:\n",
    "    \n",
    "        offset = 6\n",
    "        page_info = \"\"\n",
    "        if page.metadata[\"page\"] < offset:\n",
    "            page_info = \"Pearl of Great Price Study Edition page\"\n",
    "        else:\n",
    "            content = page.page_content\n",
    "            pager = page.metadata[\"page\"] - offset\n",
    "            page_info = \"Pearl of Great Price Study Edition page \"+str(pager)\n",
    "            metadata = {\n",
    "                \"title\": page_info,\n",
    "                \"source\": page.metadata[\"source\"]\n",
    "            }\n",
    "            \n",
    "            doc = Document(page_content=content, metadata=metadata)\n",
    "           \n",
    "            if not doc.metadata[\"title\"] or not doc.page_content:\n",
    "                if verbose:\n",
    "                    print(\"Missing title or content - skipping\", metadata[\"source\"])\n",
    "                    continue\n",
    "            docs.append(doc)\n",
    "\n",
    "    print(docs)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = load_docs_from_jsonl(input_path)\n",
    "docs = load_pages(docs, True)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveMarkdownTextSplitter(\n",
    "    title_header_separator=\" / \",\n",
    "    chunk_size=chunk_size, \n",
    "    chunk_overlap=chunk_overlap,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs, verbose=True)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, split in enumerate(splits[:10]):\n",
    "    print(ix, split.metadata[\"source\"], split.metadata[\"title\"])\n",
    "    print(split.page_content)\n",
    "    print(\"\\n!!! SPLIT !!!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(output_dir_split, f\"{today}.jsonl\")\n",
    "save_docs_to_jsonl(splits, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "models",
   "language": "python",
   "name": "models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
