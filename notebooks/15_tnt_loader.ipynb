{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "import docx\n",
    "\n",
    "from langchain.document_loaders import UnstructuredWordDocumentLoader\n",
    "from langchain.schema.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
    "import urllib.request\n",
    "\n",
    "from models.load_utils import save_docs_to_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_dir  = '../data/raw/tnt/'\n",
    "output_dir = '../data/split/tnt/'\n",
    "docxs = []\n",
    "\n",
    "chunk_size = 2000\n",
    "chunk_overlap = 200\n",
    "length_function = len\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "if not os.path.exists(path_dir):\n",
    "    os.makedirs(path_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data = []\n",
    "file_names = os.listdir(path_dir)\n",
    "for file in file_names:\n",
    "    docxs.append(path_dir + file)\n",
    "for doc in docxs:\n",
    "    loader = UnstructuredWordDocumentLoader(doc, mode=\"elements\")\n",
    "    data = []\n",
    "    data = loader.load()\n",
    "    file_data.extend(data)\n",
    "file_data\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(dir, title):\n",
    "    # path_components = urlparse(url).path.split('/')\n",
    "    return os.path.join(dir, re.sub('[^a-zA-Z0-9]', '-', title).lower()+'.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    length_function=length_function,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for url, title, first_page in pdfs:\n",
    "    path = get_path(path_dir, title)\n",
    "    print(f\"Processing {url} {path}\")\n",
    "    # download file if it doesn't exist\n",
    "    if not os.path.exists(path):\n",
    "        response = urllib.request.urlretrieve(url, path)\n",
    "        print(response)\n",
    "        print(f\"Downloaded {url}\")\n",
    "    # load file\n",
    "    loader = (path)\n",
    "    pages = []\n",
    "    for page in loader.load_and_split():\n",
    "        page_number = page.metadata['page']+1\n",
    "        if page_number < first_page:\n",
    "            continue\n",
    "        page.metadata[\"url\"] = url\n",
    "        page.metadata[\"title\"] = f\"{title} - {page_number}\"\n",
    "        pages.append(page)\n",
    "    print(f\"Processed {len(pages)} pages\")\n",
    "    splits = splits = text_splitter.split_documents(pages)\n",
    "    print(f\"Created {len(splits)} splits\")\n",
    "    for ix, split in enumerate(splits[:10]):\n",
    "        print(ix, split.metadata[\"url\"], split.metadata[\"title\"])\n",
    "        print(split.page_content)\n",
    "        print(\"\\n!!! SPLIT !!!\\n\")\n",
    "    docs.extend(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(output_dir, f\"{today}.jsonl\")\n",
    "save_docs_to_jsonl(docs, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "models",
   "language": "python",
   "name": "models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
