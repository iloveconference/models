{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure\n",
    "file_path = '../references/questions-45.txt'\n",
    "output_path = '../data/exports'\n",
    "delay_seconds = 1\n",
    "use_local_server = True\n",
    "search_results_only = False\n",
    "\n",
    "server = \"http://127.0.0.1:8000\" if use_local_server else \"https://scripturecentralqa.org/api\"\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_questions = []\n",
    "\n",
    "with open(file_path, 'rt') as txt_file:\n",
    "  for text in txt_file:\n",
    "    text = text.strip()\n",
    "    if text != '':\n",
    "        list_of_questions.append(text)\n",
    "len(list_of_questions)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "question_answers = {}\n",
    "question_results = {}\n",
    "\n",
    "for question in tqdm(list_of_questions):\n",
    "    list_data = []\n",
    "    list_data_extra = []\n",
    "    time.sleep(delay_seconds)\n",
    "    response = requests.get(f\"{server}/search\", params={'q': question, \"query_type\": 'ragonly'})\n",
    "    print(response)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"ERROR on query {question}: status_code {response.status_code}\")\n",
    "        continue\n",
    "    try:\n",
    "        res = response.content.decode('utf-8')\n",
    "        result_data = json.loads(res)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR on query {question} parsing response {res}\")\n",
    "        continue\n",
    "\n",
    "    question_results[question] = result_data['results']\n",
    "    \n",
    "    if search_results_only:\n",
    "        continue\n",
    "        \n",
    "    time.sleep(delay_seconds)\n",
    "    gpt_response = requests.get(f\"{server}/search\", params={'q': question, 'query_type': 'norag'})\n",
    "    if gpt_response.status_code != 200:\n",
    "        print(f\"ERROR on query {question}: status_code {gpt_response.status_code}\")\n",
    "        continue\n",
    "    try:\n",
    "        res = gpt_response.content.decode('utf-8')\n",
    "        gpt_result = json.loads(res)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR on gpt query {question} parsing response {res}\")\n",
    "        continue\n",
    "\n",
    "    \n",
    "    for item in result_data['results']:\n",
    "        result_temp = json.dumps(item)\n",
    "        list_data.append(result_temp)\n",
    "        if len(list_data) > 4:\n",
    "            break\n",
    "\n",
    "    result_set = '\\n--------\\n'.join(list_data)\n",
    "\n",
    "    question_answers[question] = [result_set, result_data['answer'], gpt_result[\"answer\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not search_results_only:\n",
    "    with open(output_path + '/question-answers-45.csv', 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['Question', 'Results', 'Answer', 'ChatGPT Answer'])  # header row\n",
    "        for question, answers in question_answers.items():\n",
    "            # for each question, the file should contain a line like this:\n",
    "            writer.writerow([question, answers[0], answers[1], answers[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_path + '/question-results-45.csv', 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Question', 'ResultId', 'ResultScore', 'ResultURL', 'ResultTitle', 'ResultRank', 'ResultText'])  # header row\n",
    "    for question, results in question_results.items():\n",
    "        if len(results) < 20:\n",
    "            print(question, len(results))\n",
    "        for result in results:\n",
    "            # for each question, the file should contain a line like this:\n",
    "            writer.writerow([\n",
    "                question, \n",
    "                result[\"id\"], \n",
    "                result[\"score\"], \n",
    "                result[\"url\"], \n",
    "                result[\"title\"], \n",
    "                result[\"index\"], \n",
    "                result[\"text\"],\n",
    "            ])\n",
    "\n",
    "print('End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
