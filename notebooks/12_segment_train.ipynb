{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae18a72b",
   "metadata": {},
   "source": [
    "# Train a segment classifier\n",
    "Given two texts, train a classifier to predict whether they belong to the same segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad22063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591d7b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import cohere\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "from scipy.stats import loguniform, uniform\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import spacy\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from transformers import pipeline\n",
    "\n",
    "from models.segment_train import get_mpnet_embedder, get_openai_embedder, get_labeled_pairs, \\\n",
    "    predict_using_syntactic_features, syntactic_paragraph_features,\\\n",
    "    predict_using_embeddings, predict_using_pairs, predict_using_features_and_embeddings, predict_using_features_and_ensemble\n",
    "from models.segment_eval import evaluate, compare, evaluate_embedder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b256625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure\n",
    "input_dir = '../data/segment/labeled/'\n",
    "in_filename = '2023-03-18.json'\n",
    "\n",
    "output_dir = '../data/segment/model/'\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "random_state = 42\n",
    "ngram_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e02209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid warning\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = 'false'\n",
    "\n",
    "# spacy\n",
    "parser = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# cohere\n",
    "# cohere_api_key = os.environ['COHERE_KEY']\n",
    "# co = cohere.Client(cohere_api_key)\n",
    "# cohere_embedder = get_cohere_embedder(co)\n",
    "\n",
    "# bert-wiki-paragraphs\n",
    "# pipe = pipeline(\"text-classification\", model=\"dennlinger/bert-wiki-paragraphs\")\n",
    "# bert_wiki_paras_scorer = get_bert_wiki_paras_scorer(pipe)\n",
    "\n",
    "# mpnet\n",
    "mpnet = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "mpnet_embedder = get_mpnet_embedder(mpnet)\n",
    "\n",
    "# openai\n",
    "openai.organization = os.environ['OPENAI_ORG']\n",
    "openai.api_key = os.environ['OPENAI_KEY']\n",
    "openai.Engine.list()\n",
    "openai_embedder = get_openai_embedder(openai)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541af210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read labeled data\n",
    "with open(os.path.join(input_dir, in_filename)) as f:\n",
    "    talk_sections = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a060ed",
   "metadata": {},
   "source": [
    "## First try various unsupervised approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436a4271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sections\n",
    "train_sections, test_sections = train_test_split(talk_sections, test_size=0.2, random_state=random_state)\n",
    "print('train', len(train_sections), 'test', len(test_sections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28bd39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate grouping paragraphs by purely syntactic features, such as whether the paragraph is a list item or very short or a quote\n",
    "# the idea is to use purely syntactic features to group (a few) paragraphs that should be grouped,\n",
    "# but to never group paragraphs that shouldn't be grouped\n",
    "results = evaluate(train_sections, predict_using_syntactic_features(syntactic_paragraph_features), debug=True)\n",
    "results['metrics']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbeabff",
   "metadata": {},
   "source": [
    "### Let's try a few embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc774b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph openai embeddings\n",
    "pos_sims, neg_sims = \\\n",
    "        evaluate_embedder(train_sections, results['predictions'], openai_embedder)\n",
    "plt.hist([pos_sims, neg_sims], np.linspace(0.5, 1.0, 50), label=['split', 'same'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb33bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph mpnet embeddings\n",
    "pos_sims, neg_sims = \\\n",
    "        evaluate_embedder(train_sections, results['predictions'], mpnet_embedder)\n",
    "plt.hist([pos_sims, neg_sims], np.linspace(0.0, 1.0, 100), label=['split', 'same'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0dc797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes a relatively long time and isn't as good as openai or mpnet embeddings\n",
    "\n",
    "# results = evaluate(train_sections, predict_using_pairs(score_bert_wiki_paras_scorer, 0.75),\n",
    "#                    debug=True)\n",
    "# results['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d213dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate(train_sections, predict_using_embeddings(openai_embedder, 0.83),\n",
    "                   debug=True)\n",
    "results['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfd6b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is very expensive and isn't any better than openai or mpnet embeddings\n",
    "\n",
    "# results = evaluate(train_sections, predict_using_embeddings(cohere_embedder, 3100.0),\n",
    "#                    debug=True)\n",
    "# results['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1df2c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate(train_sections, predict_using_embeddings(mpnet_embedder, 0.425),\n",
    "                   debug=True)\n",
    "results['metrics']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879c6750",
   "metadata": {},
   "source": [
    "### Try syntactic features followed by embeddings\n",
    "Use syntactic features to group some of the paragraphs,\n",
    "then use embeddings to segment the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ef9276",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate(train_sections, predict_using_features_and_embeddings(syntactic_paragraph_features, openai_embedder, 0.83),\n",
    "                   debug=True)\n",
    "results['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2433f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate(train_sections, predict_using_features_and_embeddings(syntactic_paragraph_features, mpnet_embedder, 0.425),\n",
    "                   debug=True)\n",
    "results['metrics']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66acc139",
   "metadata": {},
   "source": [
    "### Review specific predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d176a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(train_sections, results['predictions'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db665ef",
   "metadata": {},
   "source": [
    "### Run the two leading approaches on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51b1bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate(test_sections, predict_using_features_and_embeddings(syntactic_paragraph_features, openai_embedder, 0.83),\n",
    "                   debug=True)\n",
    "results['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae9b7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate(test_sections, predict_using_features_and_embeddings(syntactic_paragraph_features, mpnet_embedder, 0.425),\n",
    "                   debug=True)\n",
    "results['metrics']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609a73d1",
   "metadata": {},
   "source": [
    "## Train a custom segmentation classifier\n",
    "Use scores from the top segmentation approaches above\n",
    "as well as token and sentence counts to train an ensemble classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48db012",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = get_labeled_pairs(train_sections, openai_embedder, mpnet_embedder, parser, syntactic_paragraph_features)\n",
    "pair_df = pd.DataFrame(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d44cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c09374",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pair_df.drop(['label'], axis=1)\n",
    "y = pair_df['label']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d96d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune hyperparameters: LR or SVM\n",
    "\n",
    "# Logistic Regression\n",
    "clf = LogisticRegression(penalty='elasticnet', solver='saga', max_iter=10000)\n",
    "params = {\n",
    "    'l1_ratio': uniform(0.0, 1.0),\n",
    "    'C': loguniform(1e-2, 1e3),\n",
    "}\n",
    "\n",
    "# SVM\n",
    "# clf = LinearSVC(dual=False, max_iter=10000)\n",
    "# params = {\n",
    "#     'C': loguniform(1e-6, 1e1),\n",
    "# }\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    clf,\n",
    "    params,\n",
    "    n_iter=100,\n",
    "    scoring='f1',\n",
    "    refit=False,\n",
    "    verbose=1,\n",
    "    n_jobs=8,\n",
    "    cv=10)\n",
    "search.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074bad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(search.best_params_)\n",
    "print(search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d52ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train clf over all training data\n",
    "\n",
    "# wrap SVM in calibrated classifier CV to get probabilities\n",
    "# svm = LinearSVC(dual=False, max_iter=10000, **search.best_params_)\n",
    "# clf = CalibratedClassifierCV(svm, cv=10)\n",
    "# clf.fit(X, y)\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(penalty='elasticnet', solver='saga', max_iter=10000, **search.best_params_)),\n",
    "])\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2243c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.feature_names_in_)\n",
    "print(clf['classifier'].coef_)\n",
    "print(clf['classifier'].intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df1f5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate ensemble on training data\n",
    "results = evaluate(train_sections,\n",
    "                   predict_using_features_and_ensemble(syntactic_paragraph_features,\n",
    "                                                       openai_embedder,\n",
    "                                                       mpnet_embedder,\n",
    "                                                       parser,\n",
    "                                                       clf,\n",
    "                                                       0.55), debug=True)\n",
    "results['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e2ad41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate ensemble on test data\n",
    "results = evaluate(test_sections,\n",
    "                   predict_using_features_and_ensemble(syntactic_paragraph_features,\n",
    "                                                       openai_embedder,\n",
    "                                                       mpnet_embedder,\n",
    "                                                       parser,\n",
    "                                                       clf,\n",
    "                                                       0.55), debug=True)\n",
    "results['metrics']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b1c66e",
   "metadata": {},
   "source": [
    "## Train over all data and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dd85dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pairs = get_labeled_pairs(talk_sections, openai_embedder, mpnet_embedder, parser, syntactic_paragraph_features)\n",
    "all_pair_df = pd.DataFrame(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d3abf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_pair_df.drop(['label'], axis=1)\n",
    "y = all_pair_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a29a0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd84b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.feature_names_in_)\n",
    "print(clf['classifier'].coef_)\n",
    "print(clf['classifier'].intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fbc819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save ensemble clf\n",
    "filename = os.path.join(output_dir, f\"{today}.pkl\")\n",
    "with open(filename,'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d98408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate ensemble on all data\n",
    "results = evaluate(talk_sections,\n",
    "                   predict_using_features_and_ensemble(syntactic_paragraph_features,\n",
    "                                                       openai_embedder,\n",
    "                                                       mpnet_embedder,\n",
    "                                                       parser,\n",
    "                                                       clf,\n",
    "                                                       0.55), debug=True)\n",
    "results['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fce8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilc-models",
   "language": "python",
   "name": "ilc-models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
