{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge scored results for 45 questions notenook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_results = defaultdict(dict)  # each item in merged_results dictionary is itself another dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read your new file into a merged_results dictionary\n",
    "with open(\"../data/exports/question-results-45.csv\", 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        question = row.get('Question', '')  # Use get to handle missing 'Question' key\n",
    "        result_id = row.get('ResultId', '')  # Use get to handle missing 'ResultId' key\n",
    "        score = row.get('Score', '')  # Use get to handle missing 'Score' key\n",
    "        if question == '' or score == '':\n",
    "            continue  # skip empty scores - results you didn't score\n",
    "        # create a dictionary keyed on result id so we don't get duplicate result ids in the merged results\n",
    "        merged_results[question][result_id] = {\n",
    "            'ResultScore': row.get('ResultScore'),\n",
    "            'ResultURL': row.get('ResultURL', ''),\n",
    "            'ResultTitle': row.get('ResultTitle', ''),\n",
    "            'ResultRank': row.get('ResultRank', ''),\n",
    "            'ResultText': row.get('ResultText', ''),\n",
    "            'score': score,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(merged_results))  # there should be 45!!!\n",
    "print(sum([len(results) for results in merged_results.values()]))  # there should be 450, because you scored 10 results for each question!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the old file to the merged_results dictionary\n",
    "with open(\"../references/scored-results.csv\", 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        question = row.get('Question', '')  # Use get to handle missing 'Question' key\n",
    "        result_id = row.get('ResultId', '')  # Use get to handle missing 'ResultId' key\n",
    "        score = float(row.get('Score', ''))  # Use get to handle missing 'Score' key\n",
    "        if question not in merged_results or score == '':\n",
    "            continue  # skip questions that aren't in the 45 you scored\n",
    "        merged_results[question][result_id] = {\n",
    "            'ResultScore': row.get('ResultScore'),\n",
    "            'ResultURL': row.get('ResultURL', ''),\n",
    "            'ResultTitle': row.get('ResultTitle', ''),\n",
    "            'ResultRank': row.get('ResultRank', ''),\n",
    "            'ResultText': row.get('ResultText', ''),\n",
    "            'score': score,            \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(merged_results))   # there should still be 45\n",
    "print(sum([len(results) for results in merged_results.values()]))  # there should be a lot more than 450, because you merged the old results into the new results!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the merged scores to a references/scored-results-45.csv file\n",
    "with open('../references/scored-results-45.csv', 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Question', 'ResultId', 'ResultScore', 'ResultURL', 'ResultTitle', 'ResultRank', 'ResultText', 'Score'])  # header row\n",
    "    for question, results in merged_results.items():\n",
    "        for result_id, result in results.items():\n",
    "            writer.writerow([\n",
    "                question,\n",
    "                result_id, \n",
    "                result[\"ResultScore\"], \n",
    "                result[\"ResultURL\"], \n",
    "                result[\"ResultTitle\"], \n",
    "                result[\"ResultRank\"], \n",
    "                result[\"ResultText\"],\n",
    "                result[\"score\"],\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "models",
   "language": "python",
   "name": "models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
