{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from datetime import datetime\n",
    "from langchain.schema.document import Document\n",
    "from models.load_utils import save_docs_to_jsonl\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
    "import os\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure\n",
    "pdfs = [\n",
    "(\"https://archive.bookofmormoncentral.org/sites/default/files/archive-files/pdf/smoot/2021-12-25/pgp_study_edition_stephen_o_smoot.pdf\", \"The Pearl of Great Price: A Study Edition for Latter-day Saints\"),\n",
    "]\n",
    "\n",
    "path_dir  = '../data/raw/pdfs/'\n",
    "output_dir = '../data/split/pdfs/'\n",
    "\n",
    "chunk_size = 2000\n",
    "chunk_overlap = 200\n",
    "length_function = len\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "if not os.path.exists(path_dir):\n",
    "    os.makedirs(path_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pdf_file in pdfs:\n",
    "    print(pdf_file[0])\n",
    "    response = urllib.request.urlretrieve(pdf_file[0], path_dir + pdf_file[1].replace(' ','-').lower() + '.pdf')\n",
    "\n",
    "    print(f\"Downloaded {pdf_file[0]} to {path_dir + pdf_file[1].replace(' ','-').lower() + '.pdf'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.scandir(path_dir)\n",
    "print(\"Files in '% s':\" % path_dir)\n",
    "all_pages = []\n",
    "for entry in file_list:\n",
    "    if entry.is_file():\n",
    "        print(path_dir + entry.name)\n",
    "        loader = PyPDFLoader(path_dir + entry.name)\n",
    "        pages = loader.load_and_split()\n",
    "        all_pages.extend(pages)\n",
    " \n",
    " \n",
    "file_list.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pages(pages, verbose: bool = False) -> Document:\n",
    "    \"\"\"Load dc people from a url and html.\"\"\"\n",
    "\n",
    "    docs = []\n",
    "    for page in pages:\n",
    "    \n",
    "        offset = 6\n",
    "        page_info = \"\"\n",
    "        if page.metadata[\"page\"] < offset:\n",
    "            page_info = \"Pearl of Great Price Study Edition page\"\n",
    "        else:\n",
    "            content = page.page_content\n",
    "            pager = page.metadata[\"page\"] - offset\n",
    "            page_info = \"Pearl of Great Price Study Edition page \"+str(pager)\n",
    "            metadata = {\n",
    "                \"title\": page_info,\n",
    "                \"source\": page.metadata[\"source\"]\n",
    "            }\n",
    "            \n",
    "            doc = Document(page_content=content, metadata=metadata)\n",
    "           \n",
    "            if not doc.metadata[\"title\"] or not doc.page_content:\n",
    "                if verbose:\n",
    "                    print(\"Missing title or content - skipping\", metadata[\"source\"])\n",
    "                    continue\n",
    "            docs.append(doc)\n",
    "\n",
    "    print(docs)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = load_pages(all_pages, True)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    Language.MARKDOWN,\n",
    "    chunk_size=chunk_size, \n",
    "    chunk_overlap=chunk_overlap,\n",
    "    length_function=length_function,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, split in enumerate(splits[:10]):\n",
    "    print(ix, split.metadata[\"source\"], split.metadata[\"title\"])\n",
    "    print(split.page_content)\n",
    "    print(\"\\n!!! SPLIT !!!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(output_dir, f\"{today}.jsonl\")\n",
    "save_docs_to_jsonl(splits, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "models",
   "language": "python",
   "name": "models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
